{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Admission_Predict_Ver1.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "495         496        332          108                  5  4.5   4.0  9.02   \n",
       "496         497        337          117                  5  5.0   5.0  9.87   \n",
       "497         498        330          120                  5  4.5   5.0  9.56   \n",
       "498         499        312          103                  4  4.0   5.0  8.43   \n",
       "499         500        327          113                  4  4.5   4.5  9.04   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "495         1              0.87  \n",
       "496         1              0.96  \n",
       "497         1              0.93  \n",
       "498         0              0.73  \n",
       "499         0              0.84  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>298</td>\n",
       "      <td>320</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>312</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>83</td>\n",
       "      <td>320</td>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>304</td>\n",
       "      <td>323</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.55</td>\n",
       "      <td>1</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>336</td>\n",
       "      <td>325</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>185</td>\n",
       "      <td>316</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>468</td>\n",
       "      <td>318</td>\n",
       "      <td>101</td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>110</td>\n",
       "      <td>304</td>\n",
       "      <td>103</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>325</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>258</td>\n",
       "      <td>324</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "297         298        320          120                  3  4.0   4.5  9.11   \n",
       "20           21        312          107                  3  3.0   2.0  7.90   \n",
       "82           83        320          110                  5  5.0   4.5  9.22   \n",
       "303         304        323          107                  3  3.5   3.5  8.55   \n",
       "335         336        325          111                  4  4.0   4.5  9.11   \n",
       "184         185        316          106                  2  2.5   4.0  8.32   \n",
       "467         468        318          101                  5  3.5   5.0  8.78   \n",
       "109         110        304          103                  5  5.0   4.0  8.64   \n",
       "65           66        325          112                  4  3.5   3.5  8.92   \n",
       "257         258        324          100                  3  4.0   5.0  8.64   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "297         0              0.86  \n",
       "20          1              0.64  \n",
       "82          1              0.92  \n",
       "303         1              0.73  \n",
       "335         1              0.83  \n",
       "184         0              0.72  \n",
       "467         1              0.78  \n",
       "109         0              0.68  \n",
       "65          0              0.55  \n",
       "257         1              0.78  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0          337          118                  4  4.5   4.5  9.65         1   \n",
       "1          324          107                  4  4.0   4.5  8.87         1   \n",
       "2          316          104                  3  3.0   3.5  8.00         1   \n",
       "3          322          110                  3  3.5   2.5  8.67         1   \n",
       "4          314          103                  2  2.0   3.0  8.21         0   \n",
       "..         ...          ...                ...  ...   ...   ...       ...   \n",
       "495        332          108                  5  4.5   4.0  9.02         1   \n",
       "496        337          117                  5  5.0   5.0  9.87         1   \n",
       "497        330          120                  5  4.5   5.0  9.56         1   \n",
       "498        312          103                  4  4.0   5.0  8.43         0   \n",
       "499        327          113                  4  4.5   4.5  9.04         0   \n",
       "\n",
       "     Chance of Admit   \n",
       "0                0.92  \n",
       "1                0.76  \n",
       "2                0.72  \n",
       "3                0.80  \n",
       "4                0.65  \n",
       "..                ...  \n",
       "495              0.87  \n",
       "496              0.96  \n",
       "497              0.93  \n",
       "498              0.73  \n",
       "499              0.84  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "495        332          108                  5  4.5   4.0  9.02         1\n",
       "496        337          117                  5  5.0   5.0  9.87         1\n",
       "497        330          120                  5  4.5   5.0  9.56         1\n",
       "498        312          103                  4  4.0   5.0  8.43         0\n",
       "499        327          113                  4  4.5   4.5  9.04         0\n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['Chance of Admit ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "495    0.87\n",
       "496    0.96\n",
       "497    0.93\n",
       "498    0.73\n",
       "499    0.84\n",
       "Name: Chance of Admit , Length: 500, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>316</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>303</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>314</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>308</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>329</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>306</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>302</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>309</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>314</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "249        321          111                  3  3.5   4.0  8.83         1\n",
       "433        316          111                  4  4.0   5.0  8.54         0\n",
       "19         303          102                  3  3.5   3.0  8.50         0\n",
       "322        314          107                  2  2.5   4.0  8.27         0\n",
       "332        308          106                  3  3.5   2.5  8.21         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "106        329          111                  4  4.5   4.5  9.18         1\n",
       "270        306          105                  2  2.5   3.0  8.22         1\n",
       "348        302           99                  1  2.0   2.0  7.25         0\n",
       "435        309          105                  2  2.5   4.0  7.68         0\n",
       "102        314          106                  2  4.0   3.5  8.25         0\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_scaled=  scaler.fit_transform(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_scaled = scaler.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62      , 0.67857143, 0.5       , ..., 0.71428571, 0.65064103,\n",
       "        1.        ],\n",
       "       [0.52      , 0.67857143, 0.75      , ..., 1.        , 0.55769231,\n",
       "        0.        ],\n",
       "       [0.26      , 0.35714286, 0.5       , ..., 0.42857143, 0.54487179,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.24      , 0.25      , 0.        , ..., 0.14285714, 0.14423077,\n",
       "        0.        ],\n",
       "       [0.38      , 0.46428571, 0.25      , ..., 0.71428571, 0.28205128,\n",
       "        0.        ],\n",
       "       [0.48      , 0.5       , 0.25      , ..., 0.57142857, 0.46474359,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(7, activation='relu', input_dim= 7))\n",
    "model.add(Dense(7, activation='relu', input_dim= 7))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0040\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(Xtrain_scaled, Ytrain, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    }
   ],
   "source": [
    "Ypred = model.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9272389 ],\n",
       "       [0.8081806 ],\n",
       "       [0.5587571 ],\n",
       "       [0.7269657 ],\n",
       "       [0.82858646],\n",
       "       [0.8773604 ],\n",
       "       [0.48769635],\n",
       "       [0.65754443],\n",
       "       [0.8305764 ],\n",
       "       [0.8002798 ],\n",
       "       [0.7039041 ],\n",
       "       [0.69894236],\n",
       "       [0.66329026],\n",
       "       [0.9465268 ],\n",
       "       [0.8377884 ],\n",
       "       [0.5224565 ],\n",
       "       [0.85231584],\n",
       "       [0.606813  ],\n",
       "       [0.5448952 ],\n",
       "       [0.5571289 ],\n",
       "       [0.65858334],\n",
       "       [0.56482834],\n",
       "       [0.73984617],\n",
       "       [0.8024445 ],\n",
       "       [0.78690356],\n",
       "       [0.6174013 ],\n",
       "       [0.9512109 ],\n",
       "       [0.8680555 ],\n",
       "       [0.64515656],\n",
       "       [0.75537306],\n",
       "       [0.49031776],\n",
       "       [0.7016806 ],\n",
       "       [0.57967967],\n",
       "       [0.86596507],\n",
       "       [0.6599608 ],\n",
       "       [0.7403845 ],\n",
       "       [0.5738736 ],\n",
       "       [0.9668653 ],\n",
       "       [0.64607096],\n",
       "       [0.7306741 ],\n",
       "       [0.98777634],\n",
       "       [0.58408576],\n",
       "       [0.6730811 ],\n",
       "       [0.8689585 ],\n",
       "       [0.94939727],\n",
       "       [0.57278085],\n",
       "       [0.9704184 ],\n",
       "       [0.8448821 ],\n",
       "       [0.80325395],\n",
       "       [0.93504447],\n",
       "       [0.8980013 ],\n",
       "       [0.58287424],\n",
       "       [0.72808814],\n",
       "       [0.5823321 ],\n",
       "       [0.95846725],\n",
       "       [0.6334949 ],\n",
       "       [0.9704147 ],\n",
       "       [0.72955567],\n",
       "       [0.679934  ],\n",
       "       [0.5774024 ],\n",
       "       [0.6367913 ],\n",
       "       [0.6781823 ],\n",
       "       [0.6146931 ],\n",
       "       [0.52292794],\n",
       "       [0.44700825],\n",
       "       [0.59242046],\n",
       "       [0.8771828 ],\n",
       "       [0.8969578 ],\n",
       "       [0.66503567],\n",
       "       [0.71796423],\n",
       "       [0.6233929 ],\n",
       "       [0.7956201 ],\n",
       "       [0.6386469 ],\n",
       "       [0.5784071 ],\n",
       "       [0.5334314 ],\n",
       "       [0.6393441 ],\n",
       "       [0.84353787],\n",
       "       [0.87689155],\n",
       "       [0.5461571 ],\n",
       "       [0.64133346],\n",
       "       [0.692302  ],\n",
       "       [0.8606893 ],\n",
       "       [0.6249015 ],\n",
       "       [0.8497065 ],\n",
       "       [0.7473069 ],\n",
       "       [0.6803408 ],\n",
       "       [0.62765235],\n",
       "       [0.73967355],\n",
       "       [0.7986823 ],\n",
       "       [0.68464506],\n",
       "       [0.74769264],\n",
       "       [0.91302973],\n",
       "       [0.9214738 ],\n",
       "       [0.6824588 ],\n",
       "       [0.7882784 ],\n",
       "       [0.45184183],\n",
       "       [0.7151217 ],\n",
       "       [0.7785628 ],\n",
       "       [0.7387291 ],\n",
       "       [0.68844444]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7881155405174407"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Ytest, Ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2b30313dd0>]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
